{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0461356-db6b-4189-a5b0-933342363759",
   "metadata": {},
   "source": [
    "Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d882477-d18d-44cc-9822-8c8535c16ace",
   "metadata": {},
   "source": [
    "Python script to process three data files with messy data sets, to include mistakes throughout the data as well as column headers.\n",
    "The cleaned data is consolidated and exported as a new CSV, then the new data is used to calculate several statistics which are\n",
    "combined into a results data frame and exported in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a7134b-e47b-4065-a09b-64b7ab7e1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd749a7-1e5a-41c4-9873-0ea6c5abad60",
   "metadata": {},
   "source": [
    "Parse CSV and drop bad lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0221cc2-c8f1-491a-96b6-44d241e2defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune_df = pd.read_csv('fortune500.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf656a-4080-4bbc-8694-b23bcb910859",
   "metadata": {},
   "source": [
    "Function to parse unstructured text file based on the keys provided and using the colons as a delimeter.\n",
    "Includes a regex to process bad characters in Revenue and Profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63be1802-1d75-4822-a641-01125d7c95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_unstructured(file_path):\n",
    "    data, record = [], {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line:\n",
    "                key, value = line.split(':', 1)\n",
    "                key, value = key.strip(), value.strip()\n",
    "\n",
    "                if key == 'Year':\n",
    "                    if record:\n",
    "                        data.append(record)\n",
    "                        record = {}\n",
    "                    record[key] = int(value)\n",
    "                elif key == 'Rank':\n",
    "                    record[key] = int(value)\n",
    "                elif key == 'Company':\n",
    "                    record[key] = value\n",
    "                elif 'Revenue' in key:\n",
    "                    record['Revenue'] = float(re.sub(r'[^\\d.]', '', value))\n",
    "                elif 'Profit' in key:\n",
    "                    record['Profit'] = float(re.sub(r'[^\\d.]', '', value))\n",
    "\n",
    "            if record:\n",
    "                data.append(record)\n",
    "\n",
    "            return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf354cb-78a8-41ee-a438-f3fdff61e201",
   "metadata": {},
   "source": [
    "Convert text file to data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f904fb4-a8e7-46c3-9396-a4b433f82532",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = parse_unstructured('unstructureddata.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2547ec4-615b-4742-bd53-5e95dde8fb35",
   "metadata": {},
   "source": [
    "Function to parse JSON file and regex to replace missing values with null or replace bad characters\n",
    "(a JSON decode error while testing revealed a random question mark in several lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3d2f41-8cf0-4f97-a223-784023b400fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            cleaned_data = re.sub(r'(\\w+):,', r'\\1\": null,', line)\n",
    "            cleaned_data = re.sub(r'(\\w+)\\?:', r'\\1:', cleaned_data)\n",
    "\n",
    "            try:\n",
    "                data.append(json.loads(cleaned_data))\n",
    "            except json.JSONDecodeError as e:\n",
    "                continue\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746192a5-73d2-4bc6-969d-8cb5e20d9bcb",
   "metadata": {},
   "source": [
    "Convert JSON to data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d191ae-3b1b-4d44-a623-454969d2acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = parse_json('lines.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795d1cc-a11d-4b05-af57-55b384580279",
   "metadata": {},
   "source": [
    "Clean up the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "252d4baa-7e22-4f98-b270-31290980a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune_df.columns = ['Year', 'Rank', 'Company', 'Revenue', 'Profit']\n",
    "fortune_df.columns = [col.lower().replace(' ', '_') for col in fortune_df.columns]\n",
    "text_df.columns = [col.lower().replace(' (in millions)', '') for col in text_df.columns]\n",
    "json_df.columns = [col.lower().replace(' (in millions)', '') for col in json_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4b9f0-e12b-4150-8bbb-1add47afcb8c",
   "metadata": {},
   "source": [
    "Combine all data frames into single frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e0934c8-60ad-4211-a910-ebca38ab7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([fortune_df, text_df, json_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452062a1-c857-411a-ac32-6681460489f2",
   "metadata": {},
   "source": [
    "Copy the data frame so we can calculate the difference in records after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21585f05-3eb4-4c0a-9385-c1be7a316235",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683546d-63c2-4223-9310-3880e692af13",
   "metadata": {},
   "source": [
    "Convert relevant columns to numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa76c92-2b2d-4adb-971b-f84d6af66760",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['rank', 'revenue', 'profit']:\n",
    "    cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b22c7-748c-4c7b-b710-b8d30bf17ff7",
   "metadata": {},
   "source": [
    "Drop null data records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3f02a89-887b-438e-94bc-ecba3e91295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53a3d9-d10e-489a-b085-59dae3784551",
   "metadata": {},
   "source": [
    "Display the head and tail of the cleaned data frame to verify data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8ee819-fac5-4229-a2ee-1376542bc09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  rank         company  revenue  profit\n",
      "0   1955.0   1.0  General Motors   9823.5   806.0\n",
      "1   1955.0   2.0     Exxon Mobil   5661.4   584.8\n",
      "2   1955.0   3.0      U.S. Steel   3250.4   195.4\n",
      "4   1955.0   5.0          Esmark   2510.8    19.1\n",
      "5   1955.0   6.0        Chrysler   2071.6    18.5\n",
      "6   1955.0   7.0          Armour   2056.1     1.6\n",
      "7   1955.0   8.0        Gulf Oil   1705.3   182.8\n",
      "8   1955.0   9.0           Mobil   1703.6   183.8\n",
      "9   1955.0  10.0          DuPont   1687.7   344.4\n",
      "10  1955.0  11.0           Amoco   1667.4   132.8\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7685de-cabf-4b1c-93d8-df82a2ad658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year   rank                      company  revenue  profit\n",
      "39716  1998.0  391.0                H.F. Ahmanson   3732.9   413.8\n",
      "39717  1998.0  392.0  Supermarkets Genl. Holdings   3710.7   -43.8\n",
      "39718  1998.0  393.0                    Solectron   3694.4   158.1\n",
      "39719  1998.0  394.0             Harcourt General   3691.6  -115.1\n",
      "39720  1998.0  395.0                        Mapco   3689.7    96.9\n",
      "39721  1998.0  396.0    American Family Ins. Grp.   3689.4   251.6\n",
      "39722  1998.0  397.0                 Baker Hughes   3685.4    97.0\n",
      "39723  1998.0  398.0          Service Merchandise   3662.8   -91.6\n",
      "39724  1998.0  399.0             Silicon Graphics   3662.6    78.6\n",
      "39725  1998.0  400.0                    Brunswick   3657.4   150.5\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f48887-c150-4d24-b4c5-3c4bcacc7471",
   "metadata": {},
   "source": [
    "Export cleaned data to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb14c87c-90bd-453c-9285-5694d2dd46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5db484-683f-408b-ba91-0ed8aa64feba",
   "metadata": {},
   "source": [
    "Calculate aggregate data volume, removed lines, and unique companies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e32703bc-b1d1-4dec-871f-98f7e41dc141",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = len(cleaned_df)\n",
    "bad_data = len(combined_df) - good_data\n",
    "unique_companies = cleaned_df['company'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4956b6dd-acfc-4966-b966-85e6b88b1994",
   "metadata": {},
   "source": [
    "Reduce data set to specified year range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7323328c-5184-414a-a2cc-a4946a88eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_95to98 = cleaned_df[(cleaned_df['year'] >= 1995) & (cleaned_df['year'] <= 1998)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e322532e-7b10-49fc-abd6-5c76f4f50f44",
   "metadata": {},
   "source": [
    "Determine highest revenue and profit companies in the new year range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b3e40b7-a8cd-49c2-81b1-b41500bceb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_rev_company = df_95to98.loc[df_95to98['revenue'].idxmax(), 'company']\n",
    "highest_rev = df_95to98['revenue'].max()\n",
    "\n",
    "highest_prof_company = df_95to98.loc[df_95to98['profit'].idxmax(), 'company']\n",
    "highest_prof = df_95to98['profit'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25455cf-ea1b-47b0-9beb-4629b1d8a3c7",
   "metadata": {},
   "source": [
    "Merge the results into a combined data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c54f1178-e66f-4cb7-93b6-187229fb0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "Results_Combine = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Aggregate Data Volume',\n",
    "        'Instances of Missing Data',\n",
    "        'Unique Companies',\n",
    "        'Highest Revenue Company from 1995-98',\n",
    "        'Highest Profit Company from 1995-98'\n",
    "    ],\n",
    "    'Value': [\n",
    "        good_data,\n",
    "        bad_data,\n",
    "        unique_companies,\n",
    "        f\"{highest_rev_company} - ${highest_rev:,.2f}\",\n",
    "        f\"{highest_prof_company} - ${highest_prof:,.2f}\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68d6f9-4309-4e70-9823-cd16620e11f4",
   "metadata": {},
   "source": [
    "Print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f21685a-0547-4fd9-9dd7-13b73b3fdbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Metric                         Value\n",
      "0                 Aggregate Data Volume                         37026\n",
      "1             Instances of Missing Data                          2700\n",
      "2                      Unique Companies                          2357\n",
      "3  Highest Revenue Company from 1995-98  General Motors - $178,174.00\n",
      "4   Highest Profit Company from 1995-98       Exxon Mobil - $8,460.00\n"
     ]
    }
   ],
   "source": [
    "print(Results_Combine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fced1c-a121-441a-bde5-156b4bdfb4af",
   "metadata": {},
   "source": [
    "Export the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9f21eec-70ba-4f3b-8ba8-56305358cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Results_Combine.to_csv('Results_Combine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6377d61-abd7-4ea6-a5b4-76315ce7174d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
